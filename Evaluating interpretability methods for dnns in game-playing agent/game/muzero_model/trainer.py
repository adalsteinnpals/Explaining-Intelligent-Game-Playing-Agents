import numpy as np
import time
import torch.optim as optim
import torch

"""
TODO check target 

"""

def gen_target(ep, k, invert = False):
    '''
    Generate inputs and targets for training
    
    '''
    # path, reward, observation, action, policy
    turn_idx = np.random.randint(len(ep[0]))
    ps, vs, ax = [], [], []
    for t in range(turn_idx, turn_idx + k + 1):
        if t < len(ep[0]):
            p = ep[4][t]
            a = ep[3][t]
        else: # state after finishing game
            # p is 0 (loss is 0)
            p = np.zeros_like(ep[4][-1])
            # random action selection
            a = np.zeros(np.prod(ep[3][-1].shape), dtype=np.float32)
            a[np.random.randint(len(a))] = 1
            a = a.reshape(ep[3][-1].shape)
        vs.append([ep[1] if t % 2 == 0 else -ep[1]])
        ps.append(p)
        ax.append(a)
        
    return ep[2][turn_idx], ax, ps, vs

def train(episodes, nets, g, writer, config):
    
    '''
    Train neural nets
    
    input is espisodes and the net

    episodes is a list consistisng of a tuple of lists:
    (record, reward, features, action_features, p_targets) 

    each episode consists of recorded information from a single game 
    generated by self-play.


    
    
    '''
    
    num_epochs = config['TRAINING'].getint('num_epochs')
    batch_size = config['TRAINING'].getint('batch_size')
    max_batches_per_epoch = config['TRAINING'].getint('max_batches_per_epoch')
    train_on_cuda = config['TRAINING'].getboolean('train_on_cuda')
    
    
    learning_rate = config['TRAINING'].getfloat('learning_rate')
    momentum = config['TRAINING'].getfloat('momentum')
    weight_decay = config['TRAINING'].getfloat('weight_decay')
    
    learning_decay_rate = config['TRAINING'].getfloat('learning_decay_rate')
    
    if train_on_cuda: nets.to('cuda')
    t00 = time.time()
    
    optimizer = optim.SGD(nets.parameters(), 
                          lr=learning_rate, 
                          weight_decay=weight_decay, 
                          momentum=momentum)
    
    for epoch in range(num_epochs):
        p_loss_sum, v_loss_sum = 0, 0
        nets.train()
        for i in range(0, min(len(episodes), max_batches_per_epoch), batch_size):
            if nets.model_name == 'muzero':
                k = 5 # As suggested in paper
            else:
                k = 0
            x, ax, p_target, v_target = zip(*[gen_target(episodes[np.random.randint(len(episodes))], k) for j in range(batch_size)])
            x = torch.from_numpy(np.array(x)).float()
            ax = torch.from_numpy(np.array(ax)).float()
            p_target = torch.from_numpy(np.array(p_target))
            v_target = torch.FloatTensor(np.array(v_target))
            
            # Change the order of axis as [time step, batch, ...]
            ax = torch.transpose(ax, 0, 1)
            p_target = torch.transpose(p_target, 0, 1)
            v_target = torch.transpose(v_target, 0, 1)

            p_loss, v_loss = 0, 0

            # Compute losses for k (+ current) steps
            for t in range(k + 1):
                if t==0 and train_on_cuda: x, ax = x.to('cuda'), ax.to('cuda')
                rp = nets.representation(x) if t == 0 else nets.dynamics(rp, ax[t - 1])
                p, v = nets.prediction(rp)
                if train_on_cuda: p, v = p.cpu(), v.cpu()
                p_loss += torch.sum(-p_target[t] * torch.log(p))
                v_loss += torch.sum((v_target[t] - v) ** 2)

            p_loss_sum += p_loss.item()
            v_loss_sum += v_loss.item()


            optimizer.zero_grad()
            (p_loss + v_loss).backward()
            optimizer.step()

        for param_group in optimizer.param_groups:
            param_group['lr'] *= learning_decay_rate
            
    
    
    writer.add_scalar('p_loss', p_loss_sum / min(len(episodes), max_batches_per_epoch), g)
    writer.add_scalar('v_loss', v_loss_sum / min(len(episodes), max_batches_per_epoch), g)
    
    
    
    print('p_loss %f v_loss %f' % (p_loss_sum / min(len(episodes), max_batches_per_epoch), v_loss_sum / min(len(episodes), 5000)))

    
    if train_on_cuda: nets.to('cpu')
    
    t01 = time.time()
    print('Training: ',t01-t00)
    
    return nets


